{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning 2019 Project\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import copy\n",
    "import json\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#easier access when need to get the log value\n",
    "def log(val):\n",
    "    if val == 0:\n",
    "        return - sys.maxint - 1\n",
    "    return math.log(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process Data\n",
    "\n",
    "def process_data_emission( filePath ):\n",
    "    tags = {}  # save the number of times each tag appears\n",
    "    observations = {}  # save the word observation\n",
    "    labelled_observations = {}  # save labelled observations\n",
    "    \n",
    "    for line in open(filePath, 'r', encoding=\"utf8\"):\n",
    "        segmentedLine = line.rstrip()\n",
    "        if segmentedLine:  # if its not just an empty string\n",
    "            segmentedLine = segmentedLine.rsplit(' ', 1)\n",
    "\n",
    "            observation = segmentedLine[0]  # X\n",
    "            tag = segmentedLine[1]  # Y\n",
    "\n",
    "            if observation not in observations:  # if this observation has never been seen before\n",
    "                observations[observation] = 1\n",
    "            else:  # if this observation has been seen before\n",
    "                observations[observation] += 1\n",
    "\n",
    "            if tag not in tags:  # if this tag has never been seen before\n",
    "                tags[tag] = 1\n",
    "                labelled_observations[tag] = {observation: 1}\n",
    "\n",
    "            else:  # if this tag has been seen before\n",
    "                tags[tag] += 1\n",
    "                if observation not in labelled_observations[tag]:\n",
    "                    labelled_observations[tag][observation] = 1\n",
    "                else:\n",
    "                    labelled_observations[tag][observation] += 1\n",
    "    return observations, tags, labelled_observations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Estimate Emission\n",
    "\n",
    "Write a function that estimates the emission parameters from the training set using MLE (maximumlikelihood estimation):\n",
    "\n",
    "$ e(x|y) = Count(y→x)/Count(y) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate the emission probability\n",
    "# Check whether it is unkown or not\n",
    "\n",
    "def estimateEmission(observations, tags, labelled_observations , k=3): # As speciffied in the requirements k = 3   \n",
    "    estimates = {} # save the estimates for each \n",
    "    for tag in labelled_observations:\n",
    "        estimates[tag] = {}\n",
    "        labelled_observations[tag]['##UNK##'] = 0\n",
    "        for observation in list(labelled_observations[tag]):  # loop over all keys in labelled_observations\n",
    "            if observation == '##UNK##': \n",
    "                continue\n",
    "            if observation not in observations:  # if this observation has been found to appear less than k times before\n",
    "                labelled_observations[tag]['##UNK##'] += labelled_observations[tag].pop(observation)\n",
    "            elif observations[observation] < k:  # if first meet an observation that appear less than k times\n",
    "                labelled_observations[tag]['##UNK##'] += labelled_observations[tag].pop(observation)\n",
    "                del observations[observation]\n",
    "            else:  # compute the MLE for that emission\n",
    "                estimates[tag][observation] = float(labelled_observations[tag][observation]) / tags[tag] ## MLE\n",
    "        estimates[tag]['##UNK##'] = float(labelled_observations[tag]['##UNK##']) / tags[tag]\n",
    "\n",
    "    return list(observations), estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the sentiment analysis \n",
    "def sentimentAnalysis(inputPath, estimates, outputPath):\n",
    "    f = open(outputPath, 'w', encoding=\"utf8\") # specified to be written as dev.p2.out\n",
    "    unkPrediction = ('##UNK##', 0.0)\n",
    "    for tag in estimates:\n",
    "        if estimates[tag]['##UNK##'] > unkPrediction[1]:\n",
    "            unkPrediction = (tag, estimates[tag]['##UNK##'])\n",
    "    for line in open(inputPath, 'r', encoding=\"utf8\"):\n",
    "        observation = line.rstrip()\n",
    "        if observation:\n",
    "            prediction = ('', 0.0)  # prediction is tuple of tag and the MLE of observation for the given tag\n",
    "            for tag in estimates:\n",
    "                if observation in estimates[tag] and estimates[tag][observation] > prediction[1]:\n",
    "                    prediction = (tag, estimates[tag][observation])\n",
    "            if prediction[0]:\n",
    "                f.write('%s %s\\n' % (observation, prediction[0]))\n",
    "            else:\n",
    "                f.write('%s %s\\n' % (observation, unkPrediction[0]))\n",
    "        else:\n",
    "            f.write('\\n')\n",
    "\n",
    "    print('Finished writing to file %s' % (outputPath))\n",
    "    return f.close()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For those who are running locally\n",
    "\n",
    "# '''\n",
    "# sample python run:\n",
    "# python part2.py -d AL\n",
    "# '''\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('-d', type=str, dest='dataset', help='Dataset to run script over', required=True)\n",
    "# ## Parsing the Dataset\n",
    "\n",
    "# args = parser.parse_args()\n",
    "\n",
    "# trainFilePath = f'./Dataset/{str(args.dataset)}/{str(args.dataset)}/train'\n",
    "# inputTestFilePath = f'./Dataset/{str(args.dataset)}/{str(args.dataset)}/dev.in'\n",
    "# outputTestFilePath = f'./Dataset/{str(args.dataset)}/{str(args.dataset)}/dev.p2.out'\n",
    "# observations, tags, labelled_observations = process_data( str(trainFilePath) )\n",
    "\n",
    "# m_training, estimates = estimateEmission(observations, tags, labelled_observations)\n",
    "# sentimentAnalysis(inputTestFilePath, estimates, outputTestFilePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished writing to file ./Dataset/AL/AL/dev.p2.out\n",
      "Finished writing to file ./Dataset/CN/CN/dev.p2.out\n",
      "Finished writing to file ./Dataset/EN/EN/dev.p2.out\n",
      "Finished writing to file ./Dataset/SG/SG/dev.p2.out\n"
     ]
    }
   ],
   "source": [
    "## For those running in iPython Notebook\n",
    "datasets = ['AL', 'CN', 'EN', 'SG']\n",
    "for dataset in datasets:\n",
    "    trainFilePath = f'./Dataset/{dataset}/{dataset}/train'\n",
    "    inputTestFilePath = f'./Dataset/{dataset}/{dataset}/dev.in'\n",
    "    outputTestFilePath = f'./Dataset/{dataset}/{dataset}/dev.p2.out'\n",
    "    \n",
    "    observations, tags, labelled_observations = process_data_emission( str(trainFilePath) )\n",
    "    \n",
    "    m_training, estimates = estimateEmission(observations, tags, labelled_observations)\n",
    "    sentimentAnalysis(inputTestFilePath, estimates, outputTestFilePath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Emission, Transmission Parameter and Viterbi algorithm\n",
    "\n",
    "Transmission parameter: $ q(y_{i}|y_{i−1}) = Count(y_{i−1}, y_{i}) / Count(y_{i−1})$\n",
    "\n",
    "Viterbi Algorithm: $ y^∗_{1}, . . . , y^∗_{n}= arg max_{y_{1},...,y_{n}}p(x_{1}, . . . , x_{n}, y_{1}, . . . , y_{n}) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use estimate emission and process data from the previous part for ease of use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data_transmission( filePath ):\n",
    "    tags = {}  # count the number of times a particular y(i-1) tag has appeared\n",
    "    t_Tags = {}  # count the number of times a particular transition from y(i) to y(i-1) has appeared\n",
    "\n",
    "    previousState = ''\n",
    "    currentState = '##START##'\n",
    "    \n",
    "    # Process the data\n",
    "    for line in open(filePath, 'r'):\n",
    "        previousState = currentState if (currentState != '##STOP##') else '##START##'  # y(i-1)\n",
    "        segmentedLine = line.rstrip()\n",
    "\n",
    "        if segmentedLine:  # if its not just an empty string\n",
    "            segmentedLine = segmentedLine.rsplit(' ', 1)\n",
    "            currentState = segmentedLine[1]  # y(i)\n",
    "        else:  # if an empty string is seen\n",
    "            if previousState == '##START##': \n",
    "                break  # training data always terminates with 2 empty lines\n",
    "            currentState = '##STOP##'  # y(i)\n",
    "\n",
    "        if previousState not in tags:  # if tag y(i-1) has never been seen before\n",
    "            tags[previousState] = 1\n",
    "            t_Tags[previousState] = {currentState: 1}\n",
    "        else:\n",
    "            tags[previousState] += 1\n",
    "            if currentState not in t_Tags[previousState]:\n",
    "                t_Tags[previousState][currentState] = 1\n",
    "            else:\n",
    "                t_Tags[previousState][currentState] += 1\n",
    "    return tags, t_Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Estimate transition\n",
    "def estimateTransition(tags, t_Tags):\n",
    "    estimates = {}\n",
    "    # Compute the MLE for transitions\n",
    "    for tag in t_Tags:\n",
    "        estimates[tag] = {}\n",
    "        for transition in t_Tags[tag]:\n",
    "            estimates[tag][transition] = float(t_Tags[tag][transition]) / tags[tag]\n",
    "    return estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation of Viterbi Algorithm: \n",
    "# Generally viterbi algorithm implements trans * emission until stop\n",
    "# Affected by the previous values hence is very troublesome and computation heavy if we do not use DP\n",
    "def viterbi(observationSequence, m_training, emissionEstimates, transitionEstimates):\n",
    "    tags = list(emissionEstimates)\n",
    "    pi = [{tag: [0.0, ''] for tag in list(emissionEstimates)} for o in observationSequence]\n",
    "    \n",
    "    # Initialization\n",
    "    for c_tag in tags:\n",
    "        if c_tag not in transitionEstimates['##START##']: continue  # update tags which can be transitioned from ##START##\n",
    "\n",
    "        if observationSequence[0] in m_training:  # if this word is not ##UNK##\n",
    "            if observationSequence[0] in emissionEstimates[c_tag]:  # and this emission can be found\n",
    "                emission = emissionEstimates[c_tag][observationSequence[0]]\n",
    "            else:  # but this emission doesn't exist\n",
    "                emission = 0.0\n",
    "        else:  # if this word is ##UNK##\n",
    "            emission = emissionEstimates[c_tag]['##UNK##']\n",
    "\n",
    "        pi[0][c_tag] = [transitionEstimates['##START##'][c_tag] * emission, '##START##']\n",
    "    # Recursive case\n",
    "    for k in range(1, len(observationSequence)):  # pi[k][c_tag] = max(a(p_tag, c_tag)...)\n",
    "        for c_tag in tags:\n",
    "            for p_tag in tags:\n",
    "                if c_tag not in transitionEstimates[p_tag]: continue  # only compare p_tags which can transition to c_tag\n",
    "\n",
    "                score = pi[k-1][p_tag][0] * transitionEstimates[p_tag][c_tag]\n",
    "                if score > pi[k][c_tag][0]:\n",
    "                    pi[k][c_tag] = [score, p_tag]\n",
    "\n",
    "            if observationSequence[k] in m_training:  # if this word is not ##UNK##\n",
    "                if observationSequence[k] in emissionEstimates[c_tag]:  # and this emission can be found\n",
    "                    emission = emissionEstimates[c_tag][observationSequence[k]]\n",
    "                else:  # but this emission doesn't exist\n",
    "                    emission = 0.0\n",
    "            else:  # if this word is ##UNK##\n",
    "                emission = emissionEstimates[c_tag]['##UNK##']\n",
    "\n",
    "            pi[k][c_tag][0] *= emission\n",
    "\n",
    "    # Finally\n",
    "    result = [0.0, '']\n",
    "    for p_tag in tags:\n",
    "        if '##STOP##' not in transitionEstimates[p_tag]: continue  # only compare p_tags which can transition to ##STOP##\n",
    "\n",
    "        score = pi[-1][p_tag][0] * transitionEstimates[p_tag]['##STOP##']\n",
    "        if score > result[0]:\n",
    "            result = [score, p_tag]\n",
    "\n",
    "    # Backtracking\n",
    "    if not result[1]:  # for those weird cases where the final probability is 0\n",
    "        return\n",
    "\n",
    "    prediction = [result[1]]\n",
    "    for k in reversed(range(len(observationSequence))):\n",
    "        if k == 0: break  # skip ##START## tag\n",
    "        prediction.insert(0, pi[k][prediction[0]][1])\n",
    "\n",
    "    return prediction\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
